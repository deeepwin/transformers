{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QdJlBDrGK2ZG"
      },
      "source": [
        "# Character-level recurrent sequence-to-sequence model\n",
        "\n",
        "**Author:** Deeepwin, [fchollet](https://twitter.com/fchollet)<br>\n",
        "**Date created:** 2017/09/29<br>\n",
        "**Last modified:** 2020/04/26<br>\n",
        "**Description:** Character-level recurrent sequence-to-sequence model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wopySTv0K2ZI"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example demonstrates how to implement a basic character-level\n",
        "recurrent sequence-to-sequence model. We apply it to translating\n",
        "short English sentences into short German sentences,\n",
        "character-by-character. Note that it is fairly unusual to\n",
        "do character-level machine translation, as word-level\n",
        "models are more common in this domain.\n",
        "\n",
        "**Summary of the algorithm**\n",
        "\n",
        "- We start with input sequences from a domain (e.g. English sentences)\n",
        "    and corresponding target sequences from another domain\n",
        "    (e.g. German sentences).\n",
        "- An encoder LSTM turns input sequences to 2 state vectors\n",
        "    (we keep the last LSTM state and discard the outputs).\n",
        "- A decoder LSTM is trained to turn the target sequences into\n",
        "    the same sequence but offset by one timestep in the future,\n",
        "    a training process called \"teacher forcing\" in this context.\n",
        "    It uses as initial state the state vectors from the encoder.\n",
        "    Effectively, the decoder learns to generate `targets[t+1...]`\n",
        "    given `targets[...t]`, conditioned on the input sequence.\n",
        "- In inference mode, when we want to decode unknown input sequences, we:\n",
        "    - Encode the input sequence into state vectors\n",
        "    - Start with a target sequence of size 1\n",
        "        (just the start-of-sequence character)\n",
        "    - Feed the state vectors and 1-char target sequence\n",
        "        to the decoder to produce predictions for the next character\n",
        "    - Sample the next character using these predictions\n",
        "        (we simply use argmax).\n",
        "    - Append the sampled character to the target sequence\n",
        "    - Repeat until we generate the end-of-sequence character or we\n",
        "        hit the character limit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIlyT3CtK2ZJ"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "62oAwk31K2ZJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CzwWCdiK2ZK"
      },
      "source": [
        "## Download the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4gwPzDlXK2ZK"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Archive:  deu-eng.zip',\n",
              " 'replace deu.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL',\n",
              " '(EOF or read error, treating as \"[N]one\" ...)']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!!curl -O http://www.manythings.org/anki/deu-eng.zip\n",
        "!!unzip deu-eng.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDJXImB5K2ZL"
      },
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7UhInPcgK2ZL"
      },
      "outputs": [],
      "source": [
        "batch_size = 64         # Batch size for training.\n",
        "epochs = 100            # Number of epochs to train for.\n",
        "latent_dim = 256        # Latent dimensionality of the encoding space.\n",
        "num_samples = 10000     # Number of samples to train on.\n",
        "data_path = \"deu.txt\"   # Path to the data txt file on disk.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSW_0_COK2ZM"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hjLmNNUfK2ZN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 70\n",
            "Number of unique output tokens: 83\n",
            "Max sequence length for inputs: 15\n",
            "Max sequence length for outputs: 51\n"
          ]
        }
      ],
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    \n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\"\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)      # generates a list with all characters that are in the english text\n",
        "    for char in target_text:\n",
        "        if char not in target_characters:   # generates a list with all characters that are in the German text\n",
        "            target_characters.add(char)\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)  \n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros((len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
        "decoder_input_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_data.shape: (10000, 15, 70)\n",
            "decoder_input_data.shape: (10000, 51, 83)\n",
            "decoder_target_data.shape: (10000, 51, 83)\n"
          ]
        }
      ],
      "source": [
        "print(\"encoder_input_data.shape:\", encoder_input_data.shape)\n",
        "print(\"decoder_input_data.shape:\", decoder_input_data.shape)\n",
        "print(\"decoder_target_data.shape:\", decoder_target_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summarizing the Data\n",
        "\n",
        "- The English dataset has max. word length of 15 and a total of 70 characters (encoder_input_data)\n",
        "- The German dataset has a max. of 51 words and total of 83 characters (decoder_input_data, decoder_target_data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI1J0cHWK2ZO"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BDVJskC8K2ZP"
      },
      "outputs": [],
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))  # num_encoder_tokens=70\n",
        "\n",
        "# LSTM expects input to be (batch, time, features)\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)      # latent_dim=256, set return_state=True to output the cell states as well\n",
        "                                                                # which we later use to initialize the decoder\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)     # (None, 256), (None, 256), (None, 256), encoder_inputs=(None, None, 70) \n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))  # num_decoder_tokens=83\n",
        "\n",
        "# We set up our decoder to return full output sequences, and to return internal states as well. We don't use the return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")    # output is probability for each german character that exists in the data\n",
        "decoder_outputs = decoder_dense(decoder_outputs)                                # (None, None, 83) \n",
        "\n",
        "# Define the model that will turn `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VGzm_LZuK2ZP"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AXBCsLfmK2ZP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-19 13:50:01.318117: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8202\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 4s 11ms/step - loss: 1.3189 - accuracy: 0.6891 - val_loss: 1.1976 - val_accuracy: 0.6649\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.9099 - accuracy: 0.7572 - val_loss: 0.9277 - val_accuracy: 0.7451\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.7205 - accuracy: 0.8018 - val_loss: 0.8189 - val_accuracy: 0.7669\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.6330 - accuracy: 0.8205 - val_loss: 0.7404 - val_accuracy: 0.7907\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.5766 - accuracy: 0.8346 - val_loss: 0.6857 - val_accuracy: 0.8031\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.5378 - accuracy: 0.8450 - val_loss: 0.6553 - val_accuracy: 0.8129\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.5063 - accuracy: 0.8538 - val_loss: 0.6312 - val_accuracy: 0.8203\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4804 - accuracy: 0.8607 - val_loss: 0.6127 - val_accuracy: 0.8254\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4585 - accuracy: 0.8668 - val_loss: 0.5935 - val_accuracy: 0.8308\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4388 - accuracy: 0.8728 - val_loss: 0.5774 - val_accuracy: 0.8347\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.4208 - accuracy: 0.8782 - val_loss: 0.5733 - val_accuracy: 0.8347\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.4050 - accuracy: 0.8822 - val_loss: 0.5545 - val_accuracy: 0.8426\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3898 - accuracy: 0.8868 - val_loss: 0.5450 - val_accuracy: 0.8455\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3761 - accuracy: 0.8903 - val_loss: 0.5428 - val_accuracy: 0.8450\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3629 - accuracy: 0.8945 - val_loss: 0.5397 - val_accuracy: 0.8475\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3504 - accuracy: 0.8980 - val_loss: 0.5356 - val_accuracy: 0.8465\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.9012 - val_loss: 0.5272 - val_accuracy: 0.8498\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3270 - accuracy: 0.9045 - val_loss: 0.5287 - val_accuracy: 0.8493\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.3166 - accuracy: 0.9073 - val_loss: 0.5211 - val_accuracy: 0.8533\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.3059 - accuracy: 0.9109 - val_loss: 0.5275 - val_accuracy: 0.8529\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2963 - accuracy: 0.9135 - val_loss: 0.5239 - val_accuracy: 0.8538\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2865 - accuracy: 0.9165 - val_loss: 0.5211 - val_accuracy: 0.8555\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2772 - accuracy: 0.9195 - val_loss: 0.5233 - val_accuracy: 0.8560\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2684 - accuracy: 0.9219 - val_loss: 0.5221 - val_accuracy: 0.8569\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2599 - accuracy: 0.9243 - val_loss: 0.5228 - val_accuracy: 0.8580\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2520 - accuracy: 0.9269 - val_loss: 0.5283 - val_accuracy: 0.8564\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2445 - accuracy: 0.9290 - val_loss: 0.5286 - val_accuracy: 0.8574\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2367 - accuracy: 0.9315 - val_loss: 0.5319 - val_accuracy: 0.8579\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.2291 - accuracy: 0.9333 - val_loss: 0.5400 - val_accuracy: 0.8570\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2223 - accuracy: 0.9354 - val_loss: 0.5359 - val_accuracy: 0.8582\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2159 - accuracy: 0.9373 - val_loss: 0.5473 - val_accuracy: 0.8574\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2096 - accuracy: 0.9394 - val_loss: 0.5412 - val_accuracy: 0.8601\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.2028 - accuracy: 0.9413 - val_loss: 0.5491 - val_accuracy: 0.8580\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1967 - accuracy: 0.9431 - val_loss: 0.5533 - val_accuracy: 0.8580\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1911 - accuracy: 0.9447 - val_loss: 0.5596 - val_accuracy: 0.8579\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1854 - accuracy: 0.9467 - val_loss: 0.5652 - val_accuracy: 0.8584\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1804 - accuracy: 0.9479 - val_loss: 0.5739 - val_accuracy: 0.8572\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1752 - accuracy: 0.9495 - val_loss: 0.5704 - val_accuracy: 0.8582\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1698 - accuracy: 0.9509 - val_loss: 0.5822 - val_accuracy: 0.8570\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1651 - accuracy: 0.9520 - val_loss: 0.5864 - val_accuracy: 0.8580\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1605 - accuracy: 0.9536 - val_loss: 0.5940 - val_accuracy: 0.8557\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1563 - accuracy: 0.9547 - val_loss: 0.5921 - val_accuracy: 0.8576\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1518 - accuracy: 0.9561 - val_loss: 0.6062 - val_accuracy: 0.8568\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1478 - accuracy: 0.9573 - val_loss: 0.6105 - val_accuracy: 0.8557\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1443 - accuracy: 0.9583 - val_loss: 0.6147 - val_accuracy: 0.8568\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1401 - accuracy: 0.9593 - val_loss: 0.6167 - val_accuracy: 0.8574\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1363 - accuracy: 0.9604 - val_loss: 0.6313 - val_accuracy: 0.8553\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1329 - accuracy: 0.9615 - val_loss: 0.6326 - val_accuracy: 0.8554\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1292 - accuracy: 0.9625 - val_loss: 0.6408 - val_accuracy: 0.8546\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1265 - accuracy: 0.9632 - val_loss: 0.6468 - val_accuracy: 0.8558\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1232 - accuracy: 0.9643 - val_loss: 0.6469 - val_accuracy: 0.8554\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1203 - accuracy: 0.9649 - val_loss: 0.6578 - val_accuracy: 0.8555\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1167 - accuracy: 0.9662 - val_loss: 0.6615 - val_accuracy: 0.8556\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1140 - accuracy: 0.9668 - val_loss: 0.6708 - val_accuracy: 0.8548\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1113 - accuracy: 0.9676 - val_loss: 0.6725 - val_accuracy: 0.8543\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1088 - accuracy: 0.9682 - val_loss: 0.6796 - val_accuracy: 0.8540\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.1064 - accuracy: 0.9688 - val_loss: 0.6818 - val_accuracy: 0.8556\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1036 - accuracy: 0.9695 - val_loss: 0.6854 - val_accuracy: 0.8549\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.1015 - accuracy: 0.9702 - val_loss: 0.6959 - val_accuracy: 0.8535\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0989 - accuracy: 0.9710 - val_loss: 0.7024 - val_accuracy: 0.8538\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0970 - accuracy: 0.9716 - val_loss: 0.7071 - val_accuracy: 0.8540\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0944 - accuracy: 0.9723 - val_loss: 0.7190 - val_accuracy: 0.8531\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0927 - accuracy: 0.9725 - val_loss: 0.7146 - val_accuracy: 0.8538\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0903 - accuracy: 0.9733 - val_loss: 0.7310 - val_accuracy: 0.8539\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0887 - accuracy: 0.9739 - val_loss: 0.7319 - val_accuracy: 0.8535\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0864 - accuracy: 0.9742 - val_loss: 0.7347 - val_accuracy: 0.8533\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0853 - accuracy: 0.9748 - val_loss: 0.7388 - val_accuracy: 0.8533\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0827 - accuracy: 0.9754 - val_loss: 0.7537 - val_accuracy: 0.8522\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0813 - accuracy: 0.9757 - val_loss: 0.7484 - val_accuracy: 0.8533\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0799 - accuracy: 0.9761 - val_loss: 0.7582 - val_accuracy: 0.8525\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0781 - accuracy: 0.9763 - val_loss: 0.7647 - val_accuracy: 0.8516\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0764 - accuracy: 0.9770 - val_loss: 0.7677 - val_accuracy: 0.8536\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9775 - val_loss: 0.7692 - val_accuracy: 0.8534\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0732 - accuracy: 0.9781 - val_loss: 0.7876 - val_accuracy: 0.8521\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0723 - accuracy: 0.9782 - val_loss: 0.7866 - val_accuracy: 0.8522\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0708 - accuracy: 0.9786 - val_loss: 0.7882 - val_accuracy: 0.8526\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0692 - accuracy: 0.9788 - val_loss: 0.7977 - val_accuracy: 0.8518\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0678 - accuracy: 0.9794 - val_loss: 0.8041 - val_accuracy: 0.8516\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0666 - accuracy: 0.9798 - val_loss: 0.8065 - val_accuracy: 0.8518\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0654 - accuracy: 0.9801 - val_loss: 0.8072 - val_accuracy: 0.8513\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0643 - accuracy: 0.9803 - val_loss: 0.8190 - val_accuracy: 0.8513\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0631 - accuracy: 0.9807 - val_loss: 0.8244 - val_accuracy: 0.8521\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0623 - accuracy: 0.9809 - val_loss: 0.8264 - val_accuracy: 0.8515\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0609 - accuracy: 0.9814 - val_loss: 0.8261 - val_accuracy: 0.8531\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0599 - accuracy: 0.9813 - val_loss: 0.8305 - val_accuracy: 0.8514\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0589 - accuracy: 0.9817 - val_loss: 0.8328 - val_accuracy: 0.8519\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0578 - accuracy: 0.9820 - val_loss: 0.8372 - val_accuracy: 0.8527\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0568 - accuracy: 0.9824 - val_loss: 0.8512 - val_accuracy: 0.8519\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0555 - accuracy: 0.9828 - val_loss: 0.8541 - val_accuracy: 0.8510\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0549 - accuracy: 0.9829 - val_loss: 0.8623 - val_accuracy: 0.8512\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0543 - accuracy: 0.9831 - val_loss: 0.8608 - val_accuracy: 0.8518\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0532 - accuracy: 0.9832 - val_loss: 0.8600 - val_accuracy: 0.8511\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0525 - accuracy: 0.9835 - val_loss: 0.8687 - val_accuracy: 0.8513\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9837 - val_loss: 0.8717 - val_accuracy: 0.8514\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0510 - accuracy: 0.9840 - val_loss: 0.8799 - val_accuracy: 0.8506\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0498 - accuracy: 0.9842 - val_loss: 0.8742 - val_accuracy: 0.8518\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0492 - accuracy: 0.9844 - val_loss: 0.8857 - val_accuracy: 0.8512\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0485 - accuracy: 0.9846 - val_loss: 0.8880 - val_accuracy: 0.8500\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0479 - accuracy: 0.9847 - val_loss: 0.8959 - val_accuracy: 0.8511\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0470 - accuracy: 0.9849 - val_loss: 0.9031 - val_accuracy: 0.8508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-19 13:51:25.762011: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
            "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: s2s/assets\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f12436ab4c0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
            "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x7f12430991f0> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"s2s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YgK7FavK2ZP"
      },
      "source": [
        "## Run inference (sampling)\n",
        "\n",
        "**REMEMBER:** Why do we need to decode iteratively? \n",
        "\n",
        "Because the German word can have a different length than the English when translating. The encoder encodes the context and temporal dependencies of the sequence into the hidden states. The hidden states represent the meaning of the input. The decoder must now translate that meaning into a German sentence. Each sentence has a different meaning. Therefore the decoder will be presented for each word by different meanings (hidden state). The decoder learns to associate these meanings with a German word.\n",
        "\n",
        "**QUESTION:** Why can I not simply generate the German translation directly from the hidden states, without iteratively feed the decoder output back?\n",
        "\n",
        "This is not clear to me. In the end you have to define anyway a max sequence length on the decoder. For shorter words with empty character at the end, NN can simply learn to set character probability to zero. \n",
        "\n",
        "With encoder-decoder model, during inference, it is completely inefficient to feedback the first prediction which is a vector of words [<start> pred_1 _ _ _ _] with all the empty words denoted as _ into the LSTM. The LSTM itself, will step through all these empty wordsto make the next prediction. \n",
        "\n",
        "During training, this is ok. Because we feed the y_true as single vector to LSTM and it will step through at once (internally iterating). That is efficient.\n",
        "\n",
        "Maybe this is the answer: Because we train LSTM efficiently, in one shot, we cannot change regime or modify the model, but must infer in a similar way. That means we have to feed decoder something. Assuming the training was very successful, it makes correct predictions, we simply must get the next word, which can be used as input for the next iteration. E voila. \n",
        "\n",
        "The LSTM must only be able to predict the next word correctly! For that it just needs all inputs before current time step and not the empty words. All the remaining empty words _ and the output the LSTM will generate for them do not matter. We can simply ignore.\n",
        "\n",
        "And this we do. When we take argmax() we only look at current word and prediction probability.\n",
        "\n",
        "Best explanation I found so far is here: https://medium.com/analytics-vidhya/encoder-decoder-seq2seq-models-clearly-explained-c34186fbf49b \n",
        "\n",
        "In a summary:\n",
        "\n",
        "- The original idea of se2seq model is using LSTM (recurrent networks)\n",
        "- To make training efficient, teacher forcing is used, which dictates how decoder is defined\n",
        "- Because we have no ground truth during inference, we must think about another way to feed the decoder input (a trick or tweek)\n",
        "- We know, if decoder was trained successful, we can enter the start token and will get the next predicted word based on the hidden state\n",
        "- We only need to predict the next work correctly, not the full sentence\n",
        "- We can then feed back the correct prediction to the input to get the next correct prediction an build up the output sequence step by step"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XOOHz1PcK2ZQ"
      },
      "outputs": [],
      "source": [
        "# Define sampling models, restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwEZEQdXK2ZQ"
      },
      "source": [
        "You can now generate decoded sentences as such:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "94e7k8jJK2ZR"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Geh.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Grüß Gott!\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Grüß Gott!\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Lauf!\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Lauf!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Potzdonner!\n",
            "\n",
            "-\n",
            "Input sentence: Wow!\n",
            "Decoded sentence: Potzdonner!\n",
            "\n",
            "-\n",
            "Input sentence: Duck!\n",
            "Decoded sentence: Kopf runter!\n",
            "\n",
            "-\n",
            "Input sentence: Fire!\n",
            "Decoded sentence: Feuer!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Hilfe!\n",
            "\n",
            "-\n",
            "Input sentence: Help!\n",
            "Decoded sentence: Hilfe!\n",
            "\n",
            "-\n",
            "Input sentence: Stay.\n",
            "Decoded sentence: Bleib!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Stopp!\n",
            "\n",
            "-\n",
            "Input sentence: Stop!\n",
            "Decoded sentence: Stopp!\n",
            "\n",
            "-\n",
            "Input sentence: Wait!\n",
            "Decoded sentence: Warte!\n",
            "\n",
            "-\n",
            "Input sentence: Wait.\n",
            "Decoded sentence: Warte.\n",
            "\n",
            "-\n",
            "Input sentence: Begin.\n",
            "Decoded sentence: Fang an.\n",
            "\n",
            "-\n",
            "Input sentence: Do it.\n",
            "Decoded sentence: Mache es!\n",
            "\n",
            "-\n",
            "Input sentence: Do it.\n",
            "Decoded sentence: Mache es!\n",
            "\n",
            "-\n",
            "Input sentence: Go on.\n",
            "Decoded sentence: Geh jetzt!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for seq_index in range(20):\n",
        "    \n",
        "    # Take one sequence (part of the training set) for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "lstm_seq2seq",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 ('mli')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "vscode": {
      "interpreter": {
        "hash": "4d0dac48f5d9b27e45995153baafec01158dfff2c0bb1df66c2c7c47f74320c7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
